#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏–Ω–∏–∏ —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π –≥—Ä–∞–Ω–∏—Ü

–ê–ª–≥–æ—Ä–∏—Ç–º:
1. –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω—ã–µ —Å–∫–∞–Ω–ª–∞–π–Ω—ã —Å —Ç–µ–∫—É—â–∏–º –∫–∞–¥—Ä–æ–º
2. –ï—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç–∏ -> –±–µ–ª–æ–µ –ø–æ–ª–µ (–Ω–µ—Ç –ª–∏–Ω–∏–∏)
3. –ï—Å–ª–∏ —Ä–∞–∑–Ω–∏—Ü–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è -> –µ—Å—Ç—å –ª–∏–Ω–∏—è
4. –î–ª—è –∫–∞–∂–¥–æ–π —Å–∫–∞–Ω–∏—Ä—É—é—â–µ–π –ª–∏–Ω–∏–∏ –Ω–∞—Ö–æ–¥–∏—Ç –≥—Ä–∞–Ω–∏—Ü—ã –ª–∏–Ω–∏–∏ (–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞)
5. –ù–∞—Ö–æ–¥–∏—Ç —Ü–µ–Ω—Ç—Ä—ã –ª–∏–Ω–∏–∏ –Ω–∞ –∫–∞–∂–¥–æ–π —Å–∫–∞–Ω–ª–∞–π–Ω–µ
6. –ü–æ —Ü–µ–Ω—Ç—Ä–∞–º –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ (–ø—Ä—è–º–æ/–≤–ª–µ–≤–æ/–≤–ø—Ä–∞–≤–æ/–æ–±—Ä—ã–≤)

–¶–µ–ª—å: 100% —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
"""

import numpy as np
import cv2
import glob
import os
import sys
from pathlib import Path
import time
import matplotlib.pyplot as plt
import matplotlib.patches as patches

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã
ROI_Y_START = 11
ROI_Y_END = 102
ROI_X_START = 16
ROI_X_END = 144

# –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –ª–∏–Ω–∏–∏ (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)
MIN_LINE_WIDTH = 5
MAX_LINE_WIDTH = 60  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –ª–∏–Ω–∏–∏

# –ü–æ—Ä–æ–≥ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ (—Ä–∞–∑–Ω–∏—Ü–∞ –æ—Ç —Ñ–æ–Ω–∞)
DETECTION_THRESHOLD = 30

# –ü–æ—Ä–æ–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è "–±–µ–ª–æ–µ –ø–æ–ª–µ" (—Å—Ä–µ–¥–Ω–µ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏)
WHITE_FIELD_THRESHOLD = 10

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫–∞–Ω–∏—Ä—É—é—â–∏—Ö –ª–∏–Ω–∏–π
NUM_SCAN_LINES = 12

def compute_scan_lines(roi_y_start, roi_y_end, num_lines):
    """–í—ã—á–∏—Å–ª–∏—Ç—å Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å–∫–∞–Ω–∏—Ä—É—é—â–∏—Ö –ª–∏–Ω–∏–π"""
    return np.linspace(roi_y_start, roi_y_end - 1, num_lines, dtype=int)

def detect_line_edges_on_scanline(white_bg_row, current_row, threshold, min_width, max_width):
    """
    –î–µ—Ç–µ–∫—Ü–∏—è –≥—Ä–∞–Ω–∏—Ü –ª–∏–Ω–∏–∏ –Ω–∞ –æ–¥–Ω–æ–π —Å–∫–∞–Ω–∏—Ä—É—é—â–µ–π –ª–∏–Ω–∏–∏
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ª–∏–Ω–∏–∏: [(left, right), ...]
    """
    diff = white_bg_row.astype(np.int16) - current_row.astype(np.int16)
    mask = (diff > threshold).astype(np.uint8)
    
    # –ù–∞—Ö–æ–¥–∏–º —Å–≤—è–∑–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (—Å–µ–≥–º–µ–Ω—Ç—ã –ª–∏–Ω–∏–∏)
    segments = []
    in_segment = False
    segment_start = 0
    
    for i in range(len(mask)):
        if mask[i] == 1 and not in_segment:
            # –ù–∞—á–∞–ª–æ —Å–µ–≥–º–µ–Ω—Ç–∞
            in_segment = True
            segment_start = i
        elif mask[i] == 0 and in_segment:
            # –ö–æ–Ω–µ—Ü —Å–µ–≥–º–µ–Ω—Ç–∞
            in_segment = False
            width = i - segment_start
            if min_width <= width <= max_width:
                segments.append((segment_start, i - 1))
        
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç
    if in_segment:
        width = len(mask) - segment_start
        if min_width <= width <= max_width:
            segments.append((segment_start, len(mask) - 1))
    
    return segments

def compute_segment_center(left, right):
    """–í—ã—á–∏—Å–ª–∏—Ç—å —Ü–µ–Ω—Ç—Ä —Å–µ–≥–º–µ–Ω—Ç–∞"""
    return (left + right) / 2.0

def classify_scenario(centers, confidences, roi_width, segments_per_line):
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ü–µ–Ω–∞—Ä–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–µ–Ω—Ç—Ä–æ–≤ –ª–∏–Ω–∏–∏ –Ω–∞ —Å–∫–∞–Ω–ª–∞–π–Ω–∞—Ö
    
    Returns: (scenario, position, confidence)
        scenario: "white_field", "straight", "left", "right", "terminate"
        position: normalized position [-1, 1]
        confidence: confidence score [0, 1]
    """
    if len(centers) == 0:
        return "white_field", 0.0, 0.0
    
    # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    avg_confidence = np.mean(confidences)
    
    # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è -> –±–µ–ª–æ–µ –ø–æ–ª–µ
    if avg_confidence < 0.25:
        return "white_field", 0.0, avg_confidence
    
    # –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ä–µ–¥–Ω—é—é –ø–æ–∑–∏—Ü–∏—é
    avg_position = np.mean(centers)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫ [-1, 1]
    normalized_position = (avg_position - roi_width / 2) / (roi_width / 2)
    
    # –î–µ—Ç–µ–∫—Ü–∏—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –ª–∏–Ω–∏–∏ (—Å–æ–≤—Å–µ–º –º–∞–ª–æ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–∫–∞–Ω–ª–∞–π–Ω–æ–≤)
    detection_ratio = len(centers) / NUM_SCAN_LINES
    if detection_ratio < 0.4:
        return "terminate", normalized_position, avg_confidence
    
    # –°–ù–ê–ß–ê–õ–ê –¥–µ—Ç–µ–∫—Ü–∏—è –ø–æ–≤–æ—Ä–æ—Ç–∞ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞–¥ terminate)
    # –î–µ—Ç–µ–∫—Ü–∏—è –ø–æ–≤–æ—Ä–æ—Ç–∞ –ø–æ –∏–∑–º–µ–Ω–µ–Ω–∏—é –ø–æ–∑–∏—Ü–∏–∏ –æ—Ç –ù–ò–ñ–ù–ò–• –∫ –í–ï–†–•–ù–ò–ú —Å–∫–∞–Ω–ª–∞–π–Ω–∞–º
    # –í –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ –∫–∞–º–µ—Ä—ã:
    # - –Ω–∏–∂–Ω–∏–µ —Å–∫–∞–Ω–ª–∞–π–Ω—ã (–±–ª–∏–∂–µ –∫ —Ä–æ–±–æ—Ç—É) - –Ω–∞—á–∞–ª–æ –º–∞—Å—Å–∏–≤–∞ centers
    # - –≤–µ—Ä—Ö–Ω–∏–µ —Å–∫–∞–Ω–ª–∞–π–Ω—ã (–¥–∞–ª—å—à–µ –æ—Ç —Ä–æ–±–æ—Ç–∞) - –∫–æ–Ω–µ—Ü –º–∞—Å—Å–∏–≤–∞ centers
    position_drift = 0.0
    if len(centers) >= 4:
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é —Ç—Ä–µ—Ç—å
        n_third = max(len(centers) // 3, 1)
        bottom_avg = np.mean(centers[:n_third])   # –ë–ª–∏–∂–Ω–∏–µ —Å–∫–∞–Ω–ª–∞–π–Ω—ã
        top_avg = np.mean(centers[-n_third:])     # –î–∞–ª—å–Ω–∏–µ —Å–∫–∞–Ω–ª–∞–π–Ω—ã
        
        # –î—Ä–µ–π—Ñ = –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –æ—Ç –±–ª–∏–∂–Ω–∏—Ö –∫ –¥–∞–ª—å–Ω–∏–º
        # –ï—Å–ª–∏ –¥—Ä–µ–π—Ñ > 0: –ª–∏–Ω–∏—è —É—Ö–æ–¥–∏—Ç –í–ü–†–ê–í–û (–æ—Ç —Ä–æ–±–æ—Ç–∞) -> —Ä–æ–±–æ—Ç –ø–æ–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç –í–õ–ï–í–û
        # –ï—Å–ª–∏ –¥—Ä–µ–π—Ñ < 0: –ª–∏–Ω–∏—è —É—Ö–æ–¥–∏—Ç –í–õ–ï–í–û (–æ—Ç —Ä–æ–±–æ—Ç–∞) -> —Ä–æ–±–æ—Ç –ø–æ–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç –í–ü–†–ê–í–û
        position_drift = (top_avg - bottom_avg) / roi_width
        
        # –ü–æ—Ä–æ–≥–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ–≤–æ—Ä–æ—Ç–∞
        if position_drift > 0.08:
            return "left", normalized_position, avg_confidence
        elif position_drift < -0.08:
            return "right", normalized_position, avg_confidence
    
    # –ü–û–¢–û–ú –¥–µ—Ç–µ–∫—Ü–∏—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –ª–∏–Ω–∏–∏/T-–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
    # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ —Å–∫–∞–Ω–ª–∞–π–Ω–æ–≤ –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ –≤–µ—Ä—Ö–Ω–µ–π –∏ –Ω–∏–∂–Ω–µ–π –ø–æ–ª–æ–≤–∏–Ω–µ
    n_half = NUM_SCAN_LINES // 2
    top_detected = sum(1 for segs in segments_per_line[:n_half] if len(segs) > 0)
    bottom_detected = sum(1 for segs in segments_per_line[n_half:] if len(segs) > 0)
    
    # –ï—Å–ª–∏ –Ω–∏–∂–Ω–∏–µ –¥–µ—Ç–µ–∫—Ç–∏—Ä—É—é—Ç—Å—è –Ω–∞–º–Ω–æ–≥–æ –ª—É—á—à–µ –≤–µ—Ä—Ö–Ω–∏—Ö –ò –Ω–µ—Ç –ø–æ–≤–æ—Ä–æ—Ç–∞ -> terminate
    detection_diff = bottom_detected - top_detected
    if detection_diff >= 3 and bottom_detected >= 5 and abs(position_drift) < 0.08:
        return "terminate", normalized_position, avg_confidence
    
    # –ï—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω–æ–≥–æ –ø–æ–≤–æ—Ä–æ—Ç–∞ -> –ø—Ä—è–º–æ
    return "straight", normalized_position, avg_confidence

def process_image(white_bg, current_img, scan_lines, threshold, min_width, max_width):
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    
    Returns: (scenario, position, confidence, centers, segments_per_line)
    """
    roi_width = ROI_X_END - ROI_X_START
    
    centers = []
    confidences = []
    segments_per_line = []
    
    for y in scan_lines:
        # –ò–∑–≤–ª–µ—á—å —Å—Ç—Ä–æ–∫–∏
        white_bg_row = white_bg[y, ROI_X_START:ROI_X_END]
        current_row = current_img[y, ROI_X_START:ROI_X_END]
        
        # –î–µ—Ç–µ–∫—Ü–∏—è –≥—Ä–∞–Ω–∏—Ü –ª–∏–Ω–∏–∏
        segments = detect_line_edges_on_scanline(
            white_bg_row, current_row, threshold, min_width, max_width
        )
        
        segments_per_line.append(segments)
        
        # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Å–µ–≥–º–µ–Ω—Ç—ã
        if len(segments) > 0:
            # –ë–µ—Ä–µ–º —Å–∞–º—ã–π –±–æ–ª—å—à–æ–π —Å–µ–≥–º–µ–Ω—Ç (–æ—Å–Ω–æ–≤–Ω–∞—è –ª–∏–Ω–∏—è)
            largest_segment = max(segments, key=lambda s: s[1] - s[0])
            center = compute_segment_center(largest_segment[0], largest_segment[1])
            centers.append(center)
            
            # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å = —à–∏—Ä–∏–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞ / –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞
            width = largest_segment[1] - largest_segment[0] + 1
            confidence = min(width / max_width, 1.0)
            confidences.append(confidence)
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
    scenario, position, confidence = classify_scenario(centers, confidences, roi_width, segments_per_line)
    
    return scenario, position, confidence, centers, segments_per_line

def load_image_grayscale(path):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –≥—Ä–∞–¥–∞—Ü–∏—è—Ö —Å–µ—Ä–æ–≥–æ"""
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {path}")
    return img

def test_on_dataset(white_bg_images, test_images, expected_scenario, scan_lines):
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ
    
    Returns: (accuracy, results)
    """
    # –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ä–µ–¥–Ω–∏–π —Ñ–æ–Ω
    white_bg = np.mean([load_image_grayscale(p) for p in white_bg_images], axis=0).astype(np.uint8)
    
    results = []
    correct = 0
    total = len(test_images)
    
    for img_path in test_images:
        current_img = load_image_grayscale(img_path)
        
        scenario, position, confidence, centers, segments = process_image(
            white_bg, current_img, scan_lines, 
            DETECTION_THRESHOLD, MIN_LINE_WIDTH, MAX_LINE_WIDTH
        )
        
        is_correct = (scenario == expected_scenario)
        if is_correct:
            correct += 1
        
        results.append({
            'path': img_path,
            'scenario': scenario,
            'expected': expected_scenario,
            'position': position,
            'confidence': confidence,
            'centers': centers,
            'segments': segments,
            'correct': is_correct
        })
    
    accuracy = correct / total if total > 0 else 0
    return accuracy, results

def visualize_results(white_bg, test_images, results, output_path, max_examples=3):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    n_examples = min(len(test_images), max_examples)
    
    fig, axes = plt.subplots(n_examples, 1, figsize=(12, 4 * n_examples))
    if n_examples == 1:
        axes = [axes]
    
    scan_lines = compute_scan_lines(ROI_Y_START, ROI_Y_END, NUM_SCAN_LINES)
    
    for idx in range(n_examples):
        img_path = test_images[idx]
        result = results[idx]
        
        current_img = load_image_grayscale(img_path)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ RGB –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        img_rgb = cv2.cvtColor(current_img, cv2.COLOR_GRAY2RGB)
        
        # –ù–∞—Ä–∏—Å–æ–≤–∞—Ç—å ROI
        cv2.rectangle(img_rgb, (ROI_X_START, ROI_Y_START), (ROI_X_END, ROI_Y_END), (0, 255, 0), 1)
        
        # –ù–∞—Ä–∏—Å–æ–≤–∞—Ç—å —Å–∫–∞–Ω–∏—Ä—É—é—â–∏–µ –ª–∏–Ω–∏–∏
        for y in scan_lines:
            cv2.line(img_rgb, (ROI_X_START, y), (ROI_X_END, y), (255, 255, 0), 1)
        
        # –ù–∞—Ä–∏—Å–æ–≤–∞—Ç—å –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
        for i, (y, segments) in enumerate(zip(scan_lines, result['segments'])):
            for seg_left, seg_right in segments:
                x_left = ROI_X_START + seg_left
                x_right = ROI_X_START + seg_right
                cv2.line(img_rgb, (x_left, y), (x_right, y), (255, 0, 0), 2)
        
        # –ù–∞—Ä–∏—Å–æ–≤–∞—Ç—å —Ü–µ–Ω—Ç—Ä—ã
        for i, center in enumerate(result['centers']):
            y = scan_lines[i] if i < len(scan_lines) else scan_lines[-1]
            x = int(ROI_X_START + center)
            cv2.circle(img_rgb, (x, y), 3, (0, 0, 255), -1)
        
        # –ü–æ–∫–∞–∑–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        axes[idx].imshow(img_rgb)
        axes[idx].axis('off')
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        status = "‚úì" if result['correct'] else "‚úó"
        title = f"{status} {os.path.basename(img_path)}\n"
        title += f"–î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ: {result['scenario']} | –û–∂–∏–¥–∞–ª–æ—Å—å: {result['expected']}\n"
        title += f"–ü–æ–∑–∏—Ü–∏—è: {result['position']:.3f} | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.3f} | –¶–µ–Ω—Ç—Ä–æ–≤: {len(result['centers'])}"
        axes[idx].set_title(title, fontsize=10)
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"   –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {output_path}")

def main():
    print("=" * 80)
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –£–õ–£–ß–®–ï–ù–ù–û–ì–û –ê–õ–ì–û–†–ò–¢–ú–ê –° –î–ï–¢–ï–ö–¶–ò–ï–ô –ì–†–ê–ù–ò–¶ –õ–ò–ù–ò–ò")
    print("=" * 80)
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    print("\n‚öôÔ∏è  –ü–ê–†–ê–ú–ï–¢–†–´ –ê–õ–ì–û–†–ò–¢–ú–ê:")
    print(f"   ROI: Y[{ROI_Y_START}:{ROI_Y_END}], X[{ROI_X_START}:{ROI_X_END}]")
    print(f"   –°–∫–∞–Ω–∏—Ä—É—é—â–∏—Ö –ª–∏–Ω–∏–π: {NUM_SCAN_LINES}")
    print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –ª–∏–Ω–∏–∏: {MIN_LINE_WIDTH} –ø–∏–∫—Å–µ–ª–µ–π")
    print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –ª–∏–Ω–∏–∏: {MAX_LINE_WIDTH} –ø–∏–∫—Å–µ–ª–µ–π")
    print(f"   –ü–æ—Ä–æ–≥ –¥–µ—Ç–µ–∫—Ü–∏–∏: {DETECTION_THRESHOLD}")
    
    # –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º
    script_dir = Path(__file__).parent
    data_dir = script_dir.parent / "data"
    output_dir = script_dir / "output"
    output_dir.mkdir(exist_ok=True)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–±–µ–ª–æ–µ –ø–æ–ª–µ)
    calib_pattern = str(data_dir / "img_calibration" / "calibration_*.jpg")
    calib_images = sorted(glob.glob(calib_pattern))
    
    if len(calib_images) == 0:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω—ã –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {calib_pattern}")
        return 1
    
    print(f"\nüìä –ö–ê–õ–ò–ë–†–û–í–ö–ê:")
    print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(calib_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–µ–ª–æ–≥–æ –ø–æ–ª—è")
    
    # –í—ã—á–∏—Å–ª–∏—Ç—å —Å–∫–∞–Ω–∏—Ä—É—é—â–∏–µ –ª–∏–Ω–∏–∏
    scan_lines = compute_scan_lines(ROI_Y_START, ROI_Y_END, NUM_SCAN_LINES)
    print(f"   –°–∫–∞–Ω–∏—Ä—É—é—â–∏–µ –ª–∏–Ω–∏–∏ (Y): {scan_lines.tolist()}")
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã
    datasets = [
        ("straight", "img_straight", "–ü—Ä—è–º–∞—è –ª–∏–Ω–∏—è"),
        ("left", "img_left", "–ü–æ–≤–æ—Ä–æ—Ç –≤–ª–µ–≤–æ"),
        ("right", "img_right", "–ü–æ–≤–æ—Ä–æ—Ç –≤–ø—Ä–∞–≤–æ"),
        ("terminate", "img_terminate", "–û–∫–æ–Ω—á–∞–Ω–∏–µ –ª–∏–Ω–∏–∏"),
    ]
    
    print("\n" + "=" * 80)
    print("üìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 80)
    
    total_images = 0
    total_correct = 0
    all_results = {}
    
    for scenario, folder, description in datasets:
        pattern = str(data_dir / folder / "*.jpg")
        test_images = sorted(glob.glob(pattern))
        
        if len(test_images) == 0:
            print(f"\n‚ö†Ô∏è  {description}: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            continue
        
        print(f"\nüìÇ {description}:")
        print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(test_images)}")
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        accuracy, results = test_on_dataset(calib_images, test_images, scenario, scan_lines)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        scenarios_detected = {}
        for r in results:
            detected = r['scenario']
            scenarios_detected[detected] = scenarios_detected.get(detected, 0) + 1
        
        print(f"   –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy * 100:.1f}%")
        print(f"   –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ –∫–∞–∫:")
        for det_scenario, count in sorted(scenarios_detected.items()):
            pct = count / len(test_images) * 100
            symbol = "‚úì" if det_scenario == scenario else "‚úó"
            print(f"      {symbol} {det_scenario}: {count} ({pct:.1f}%)")
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        all_results[scenario] = {
            'accuracy': accuracy,
            'results': results,
            'images': test_images
        }
        
        total_images += len(test_images)
        total_correct += int(accuracy * len(test_images))
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
        output_path = output_dir / f"edge_detection_{scenario}.png"
        visualize_results(
            np.mean([load_image_grayscale(p) for p in calib_images], axis=0).astype(np.uint8),
            test_images, results, output_path, max_examples=3
        )
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 80)
    print("üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 80)
    print(f"   –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total_images}")
    print(f"   –ü—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {total_correct}")
    print(f"   –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {total_correct / total_images * 100:.1f}%")
    
    # –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
    print("\n" + "=" * 80)
    print("üîç –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö")
    print("=" * 80)
    
    for scenario, data in all_results.items():
        errors = [r for r in data['results'] if not r['correct']]
        if len(errors) > 0:
            print(f"\n{scenario.upper()}:")
            for err in errors[:5]:  # –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫
                print(f"   ‚úó {os.path.basename(err['path'])}")
                print(f"      –î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ: {err['scenario']} (–ø–æ–∑–∏—Ü–∏—è: {err['position']:.3f}, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {err['confidence']:.3f})")
    
    print("\n" + "=" * 80)
    print("‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print("=" * 80)
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
